{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntrain_data=train_data.drop(labels=['PassengerId','Name','Ticket'], axis=1)\ntrain_data.info()\ntest_data=test_data.drop(labels=['PassengerId','Name','Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert cabin to deck -> label int\n\ntest_data['Cabin'].fillna('U0', inplace=True)\ntrain_data['Cabin'].fillna('U0', inplace=True)\ntest_data['Deck']= test_data['Cabin'].str.extract('([A-Za-z]+)')\ntrain_data['Deck']= train_data['Cabin'].str.extract('([A-Za-z]+)')\n#test U and T value\ndeck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8, \"T\": 8}\ntest_data['Deck'] = test_data['Deck'].map(deck)\ntest_data['Deck'] = test_data['Deck'].astype(int)\ntrain_data['Deck'] = train_data['Deck'].map(deck)\ntrain_data['Deck'] = train_data['Deck'].astype(int)\n\ntrain_data=train_data.drop(labels='Cabin', axis=1)\ntest_data=test_data.drop(labels='Cabin', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rel not needed\n# train_data['Rel'] = train_data['SibSp']+train_data['Parch']\ntrain_data=train_data.drop(labels='SibSp', axis=1)\ntrain_data=train_data.drop(labels='Parch', axis=1)\n# test_data['Rel'] = test_data['SibSp']+test_data['Parch']\ntest_data=test_data.drop(labels='SibSp', axis=1)\ntest_data=test_data.drop(labels='Parch', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncorrMatrix = train_data.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=train_data.iloc[:,0:1].values\nx_train=train_data.iloc[:,1:].values\nx_test=test_data.iloc[:,:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nx_train[:,1]=le.fit_transform(x_train[:,1])\nx_test[:,1]=le.transform(x_test[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import KNNImputer\nknn1 = KNNImputer(n_neighbors=5, weights='uniform')\nx_train[:, 2:3]=knn1.fit_transform(x_train[:, 2:3]) #age\nx_test[:, 2:3]=knn1.transform(x_test[:, 2:3])\n\nfrom sklearn.impute import SimpleImputer\nsi1 = SimpleImputer(missing_values=np.nan, strategy='mean')\nx_train[:, 3:4] = si1.fit_transform(x_train[:, 3:4]) #fare\nx_test[:, 3:4] = si1.transform(x_test[:, 3:4])\n\n\nfrom sklearn.impute import SimpleImputer\nsi2 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nx_train[:, 4:5] = si2.fit_transform(x_train[:, 4:5]) #embarked\nx_test[:, 4:5] = si2.transform(x_test[:, 4:5])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fare scaled\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train[:,3:4] = sc.fit_transform(x_train[:,3:4])\nx_test[:,3:4] = sc.transform(x_test[:,3:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode embarked\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nx_train[:,4:5]  = x_train[:,4:5].astype('str')\nct = ColumnTransformer([('encoder', OneHotEncoder(), [4])], remainder='passthrough')\nx_train=ct.fit_transform(x_train)\nx_test=ct.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier=RandomForestClassifier(max_depth=80, max_features=2, min_samples_leaf=4,\n                        min_samples_split=8, n_estimators= 100)\n\nclassifier.fit(x_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_train=classifier.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_train)\ncm = confusion_matrix(y_train, pred_train)\nprint(cm)\naccuracy_score(y_train, pred_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp = {\n  \"embarked1\": classifier.feature_importances_[0]*100,\n  \"embarked2\": classifier.feature_importances_[1]*100,\n  \"embarked3\": classifier.feature_importances_[2]*100,\n    \"class\": classifier.feature_importances_[3]*100,\n    \"gender\": classifier.feature_importances_[4]*100,\n    \"Age\": classifier.feature_importances_[5]*100,\n    \"Fare\": classifier.feature_importances_[6]*100,\n    \"Deck\": classifier.feature_importances_[7]*100,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nplt.bar(*zip(*imp.items()), )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot('Pclass', 'Fare', data=train_data, aspect=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #tuning params\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.ensemble import RandomForestClassifier\n# param_grid = {\n#     'bootstrap': [True],\n#     'max_depth': [80, 90, 100, 110],\n#     'max_features': [2, 3],\n#     'min_samples_leaf': [3, 4, 5],\n#     'min_samples_split': [8, 10, 12],\n#     'n_estimators': [100,110,120,130]\n# }\n# rf = RandomForestClassifier()\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1, verbose = 2)\n\n# grid_search.fit(x_train, y_train)\n# grid_search.best_params_\n# best_grid = grid_search.best_estimator_\n# best_grid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results=classifier.predict(x_test)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_data = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\nresult_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': result_data.PassengerId, 'Survived': results})\noutput.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}